#!/usr/bin/env python
import argparse
import datetime
import os
import subprocess
import psutil
import sys
import threading
import time
from itertools import combinations
import copy

max_memory_usage = 0
def monitor_memory_usage(interval=1):
    global max_memory_usage
    while True:
        total_memory = get_total_memory_usage()
        max_memory_usage = max(max_memory_usage, total_memory)
        time.sleep(interval)

def get_total_memory_usage():
    parent_process = psutil.Process(os.getpid())
    parent_memory = parent_process.memory_info().rss
    total_memory = parent_memory

    for child in parent_process.children(recursive=True):
        try:
            child_memory = child.memory_info().rss
            total_memory += child_memory
        except psutil.NoSuchProcess:
            continue
    return total_memory

# Start the memory monitoring in a separate thread
monitoring_thread = threading.Thread(target=monitor_memory_usage, args=(1,), daemon=True)
monitoring_thread.start()

def logging(message):
    print(f"[{datetime.datetime.now()}] {message}", flush=True)

def run_cmd(command, name, verbose=True):
    if verbose:
        logging(f'{name}')
    if "-o" in command:
        index = command.index("-o")
        out = command[index + 1]
        log_file = out + ".log"
        with open(log_file, 'w') as f:
            ret = subprocess.run(command, stdout=f)
    else:
        ret = subprocess.run(command)
    if ret.returncode:
        logging(f'{name} fails: {" ".join(command)}')
        sys.exit(1)


parser = argparse.ArgumentParser()
parser.add_argument(
    "-g",
    "--genome",
    required=True,
    action="append",
    help="Path to the genome"
)
parser.add_argument(
    "-i",
    "--iterations",
    required=False,
    type=int,
    default=5,
    help="The number of iterations for three genomes only"
)
parser.add_argument(
    "-k",
    "--k_values",
    required=False,
    default="31,51,101,201,401,801,2001",
    help="K-mer values for graph transformations (default 31,51,101,201,401,801,2001)"
)
parser.add_argument(
    "-s",
    "--simple",
    required=False,
    default="0",
    type=str,
    help="Similarity threshold for collapsing simple bulges (default 0)"
)
parser.add_argument(
    "-c",
    "--complex",
    required=False,
    default="0.65",
    type=str,
    help="Similarity threshold for collapsing complex bulges (default 0.65)"
)
parser.add_argument(
    "-o",
    "--output",
    required=True,
    help="Output directory of GenomeDecoder"
)

args = parser.parse_args()

if (os.path.isdir(args.output)):
    logging(f"Output directory {args.output} already exists.")
    exit(1)

k_values = args.k_values.split(',')
if len(k_values) < 2:
    logging(f"K should be more than 2 values.")

pid = os.getpid()
process = psutil.Process(pid)
logging("GenomeDecoder starts")
logging(f"RSS (Resident Set Size): {max_memory_usage} bytes")
# create output directory
run_cmd(["mkdir", args.output], "Making output dir")

genomes_to_run = args.genome

if len(genomes_to_run) == 1:
    genome1_ori = os.path.realpath(genomes_to_run[0])
    genome1 = os.path.realpath(genomes_to_run[0])
    k = k_values[0]
    out_dir_graph = f"{args.output}/jumbodbg.consensus.k{k}"
    dot_graph = f"{out_dir_graph}/graph.dot"
    fa_graph = f"{out_dir_graph}/graph.fasta"
    out_dir_consensus = f"{args.output}/consensus.k{k}"
    run_cmd(["jumboDBG", "--reads", genome1, "-t", "25", "-k", k, "-o", out_dir_graph, "--coverage"], f"Graph construction for k={k}")
    run_cmd(["consensus_asm", "-d", dot_graph, "-f", fa_graph, "-1", genome1, "-k", k, "-o", out_dir_consensus, "--only_simple_bulge", "-s", "0.9"], f"Graph transformation for k={k}")
    genome1 = f"{out_dir_consensus}/graph.final.haplome1.fa"

    for k in k_values[1:]:
        out_dir_graph = f"{args.output}/jumbodbg.consensus.k{k}"
        dot_graph = f"{out_dir_graph}/graph.dot"
        fa_graph = f"{out_dir_graph}/graph.fasta"
        out_dir_consensus = f"{args.output}/consensus.k{k}"
        run_cmd(["jumboDBG", "--reads", genome1, "-t", "25", "-k", k, "-o", out_dir_graph, "--coverage"], f"Graph construction for k={k}")
        run_cmd(["consensus_asm", "-d", dot_graph, "-f", fa_graph, "-1", genome1, "-k", k, "-o", out_dir_consensus, "-s", args.simple, "-c", args.complex], f"Graph transformation for k={k}")
        genome1 = f"{out_dir_consensus}/graph.final.haplome1.fa"

    out = f"{k}.1"
    out_dir_graph = f"{args.output}/jumbodbg.consensus.k{out}"
    dot_graph = f"{out_dir_graph}/graph.dot"
    fa_graph = f"{out_dir_graph}/graph.fasta"
    out_dir_consensus = f"{args.output}/consensus.k{out}"
    run_cmd(["jumboDBG", "--reads", genome1, "-t", "25", "-k", k, "-o", out_dir_graph, "--coverage"], f"Graph construction for k={k}")
    run_cmd(["consensus_asm", "-d", dot_graph, "-f", fa_graph, "-1", genome1, "-k", k, "-o", out_dir_consensus, "-s", args.simple, "-c", args.complex], f"Graph transformation for k={k}")
    genome1 = f"{out_dir_consensus}/graph.final.haplome1.fa"
    logging(f"RSS (Resident Set Size): {max_memory_usage} bytes")

    edlib_1 = f"{out_dir_consensus}.edlib1"
    run_cmd(["edlib", genome1_ori, genome1, edlib_1], "Aligning transformed sequence 1 to original sequence 1")
    run_cmd(["parse_cigar.py", f"{edlib_1}/cigar.txt", f"{out_dir_consensus}/graph.with_haplome.haplome1.blocks", "edlib"], "Finalizing genome 1")
    run_cmd(["mv", f"{out_dir_consensus}/graph.with_haplome.haplome1.blocks.edlib.csv", f"{args.output}/final_blocks_1.csv"], "Copying result 1")
    logging(f"RSS (Resident Set Size): {max_memory_usage} bytes")

elif len(genomes_to_run) == 2:
    genome1_ori = os.path.realpath(genomes_to_run[0])
    genome2_ori = os.path.realpath(genomes_to_run[1])
    genome1 = os.path.realpath(genomes_to_run[0])
    genome2 = os.path.realpath(genomes_to_run[1])

    k = k_values[0]
    out_dir_graph = f"{args.output}/jumbodbg.consensus.k{k}"
    dot_graph = f"{out_dir_graph}/graph.dot"
    fa_graph = f"{out_dir_graph}/graph.fasta"
    out_dir_consensus = f"{args.output}/consensus.k{k}"
    run_cmd(["jumboDBG", "--reads", genome1, "--reads", genome2, "-t", "25", "-k", k, "-o", out_dir_graph, "--coverage"], f"Graph construction for k={k}")
    run_cmd(["consensus_asm", "-d", dot_graph, "-f", fa_graph, "-1", genome1, "-2", genome2, "-k", k, "-o", out_dir_consensus, "--only_simple_bulge", "-s", "0.9"], f"Graph transformation for k={k}")
    genome1 = f"{out_dir_consensus}/graph.final.haplome1.fa"
    genome2 = f"{out_dir_consensus}/graph.final.haplome2.fa"

    for k in k_values[1:]:
        out_dir_graph = f"{args.output}/jumbodbg.consensus.k{k}"
        dot_graph = f"{out_dir_graph}/graph.dot"
        fa_graph = f"{out_dir_graph}/graph.fasta"
        out_dir_consensus = f"{args.output}/consensus.k{k}"
        run_cmd(["jumboDBG", "--reads", genome1, "--reads", genome2, "-t", "25", "-k", k, "-o", out_dir_graph, "--coverage"], f"Graph construction for k={k}")
        run_cmd(["consensus_asm", "-d", dot_graph, "-f", fa_graph, "-1", genome1, "-2", genome2, "-k", k, "-o", out_dir_consensus, "-s", args.simple, "-c", args.complex], f"Graph transformation for k={k}")
        genome1 = f"{out_dir_consensus}/graph.final.haplome1.fa"
        genome2 = f"{out_dir_consensus}/graph.final.haplome2.fa"

    out = f"{k}.1"
    out_dir_graph = f"{args.output}/jumbodbg.consensus.k{out}"
    dot_graph = f"{out_dir_graph}/graph.dot"
    fa_graph = f"{out_dir_graph}/graph.fasta"
    out_dir_consensus = f"{args.output}/consensus.k{out}"
    run_cmd(["jumboDBG", "--reads", genome1, "--reads", genome2, "-t", "25", "-k", k, "-o", out_dir_graph, "--coverage"], f"Graph construction for k={k}")
    run_cmd(["consensus_asm", "-d", dot_graph, "-f", fa_graph, "-1", genome1, "-2", genome2, "-k", k, "-o", out_dir_consensus, "-s", args.simple, "-c", args.complex], f"Graph transformation for k={k}")
    genome1 = f"{out_dir_consensus}/graph.final.haplome1.fa"
    genome2 = f"{out_dir_consensus}/graph.final.haplome2.fa"
    logging(f"RSS (Resident Set Size): {max_memory_usage} bytes")

    edlib_1 = f"{out_dir_consensus}.edlib1"
    run_cmd(["edlib", genome1_ori, genome1, edlib_1], "Aligning transformed sequence 1 to original sequence 1")
    run_cmd(["parse_cigar.py", f"{edlib_1}/cigar.txt", f"{out_dir_consensus}/graph.with_haplome.haplome1.blocks", "edlib"], "Finalizing genome 1")
    run_cmd(["mv", f"{out_dir_consensus}/graph.with_haplome.haplome1.blocks.edlib.csv", f"{args.output}/final_blocks_1.csv"], "Copying result 1")
    edlib_2 = f"{out_dir_consensus}.edlib2"
    run_cmd(["edlib", genome2_ori, genome2, edlib_2], "Aligning transformed sequence 2 to original sequence 2")
    run_cmd(["parse_cigar.py", f"{edlib_2}/cigar.txt", f"{out_dir_consensus}/graph.with_haplome.haplome2.blocks", "edlib"], "Finalizing genome 2s")
    run_cmd(["mv", f"{out_dir_consensus}/graph.with_haplome.haplome2.blocks.edlib.csv", f"{args.output}/final_blocks_2.csv"], "Copying result 2")
    logging(f"RSS (Resident Set Size): {max_memory_usage} bytes")

else:
    # how many iterations of full combinations
    genomes_ori = copy.deepcopy(genomes_to_run)
    for it in range(args.iterations):
        for index1, index2 in combinations(range(len(genomes_to_run)), 2):
            genome1 = os.path.realpath(genomes_to_run[index1])
            genome2 = os.path.realpath(genomes_to_run[index2])
            print(f"Run synteny for {genome1} ({genomes_ori[index1]}) and {genome2} ({genomes_ori[index2]})")
            
            output = f"{args.output}/{it}_genome{index1+1}_genome{index2+1}"
            run_cmd(["mkdir", output], "Making output dir")
            k = k_values[0]
            out_dir_graph = f"{output}/jumbodbg.consensus.k{k}"
            dot_graph = f"{out_dir_graph}/graph.dot"
            fa_graph = f"{out_dir_graph}/graph.fasta"
            out_dir_consensus = f"{output}/consensus.k{k}"
            run_cmd(["jumboDBG", "--reads", genome1, "--reads", genome2, "-t", "25", "-k", k, "-o", out_dir_graph, "--coverage"], f"Graph construction for k={k}")
            run_cmd(["consensus_asm", "-d", dot_graph, "-f", fa_graph, "-1", genome1, "-2", genome2, "-k", k, "-o", out_dir_consensus, "--only_simple_bulge", "-s", "0.9"], f"Graph transformation for k={k}")
            genome1 = f"{out_dir_consensus}/graph.final.haplome1.fa"
            genome2 = f"{out_dir_consensus}/graph.final.haplome2.fa"

            for k in k_values[1:]:
                out_dir_graph = f"{output}/jumbodbg.consensus.k{k}"
                dot_graph = f"{out_dir_graph}/graph.dot"
                fa_graph = f"{out_dir_graph}/graph.fasta"
                out_dir_consensus = f"{output}/consensus.k{k}"
                run_cmd(["jumboDBG", "--reads", genome1, "--reads", genome2, "-t", "25", "-k", k, "-o", out_dir_graph, "--coverage"], f"Graph construction for k={k}")
                run_cmd(["consensus_asm", "-d", dot_graph, "-f", fa_graph, "-1", genome1, "-2", genome2, "-k", k, "-o", out_dir_consensus, "-s", args.simple, "-c", args.complex], f"Graph transformation for k={k}")
                genome1 = f"{out_dir_consensus}/graph.final.haplome1.fa"
                genome2 = f"{out_dir_consensus}/graph.final.haplome2.fa"

            out = f"{k}.1"
            out_dir_graph = f"{output}/jumbodbg.consensus.k{out}"
            dot_graph = f"{out_dir_graph}/graph.dot"
            fa_graph = f"{out_dir_graph}/graph.fasta"
            out_dir_consensus = f"{output}/consensus.k{out}"
            run_cmd(["jumboDBG", "--reads", genome1, "--reads", genome2, "-t", "25", "-k", k, "-o", out_dir_graph, "--coverage"], f"Graph construction for k={k}")
            run_cmd(["consensus_asm", "-d", dot_graph, "-f", fa_graph, "-1", genome1, "-2", genome2, "-k", k, "-o", out_dir_consensus, "-s", args.simple, "-c", args.complex], f"Graph transformation for k={k}")
            genome1 = f"{out_dir_consensus}/graph.final.haplome1.fa"
            genome2 = f"{out_dir_consensus}/graph.final.haplome2.fa"
            logging(f"RSS (Resident Set Size): {max_memory_usage} bytes")

            genomes_to_run[index1] = genome1
            genomes_to_run[index2] = genome2
    
    # jumboDBG
    out_dir_graph = f"{args.output}/jumbodbg_final"
    print("Run cmd:", " ".join(["jumboDBG", "--reads", " --reads ".join(genomes_to_run), "-t", "25", "-k", k, "-o", out_dir_graph, "--coverage"]))
    os.system(" ".join(["jumboDBG", "--reads", " --reads ".join(genomes_to_run), "-t", "25", "-k", k, "-o", out_dir_graph, "--coverage"]))
    # consensus (fixed for 3 genomes)
    dot_graph = f"{out_dir_graph}/graph.dot"
    fa_graph = f"{out_dir_graph}/graph.fasta"
    out_dir_consensus = f"{args.output}/consensus_final"
    run_cmd(["consensus_asm", "-d", dot_graph, "-f", fa_graph, "-1", genomes_to_run[0], "-2", genomes_to_run[1], "-3", genomes_to_run[2], "-k", k, "-o", out_dir_consensus, "-s", args.simple, "-c", args.complex, "--only_synteny"], f"Graph transformation for k={k}")
    #edlib
    logging(f"RSS (Resident Set Size): {max_memory_usage} bytes")
    for i in range(len(genomes_to_run)):
        edlib = f"{out_dir_consensus}.edlib{i+1}"
        run_cmd(["edlib", genomes_ori[i], genomes_to_run[i], edlib], f"Aligning transformed sequence {i+1} to original sequence {i+1}: {genomes_ori[i]}")
        run_cmd(["parse_cigar.py", f"{edlib}/cigar.txt", f"{out_dir_consensus}/graph.with_haplome.haplome{i+1}.blocks", "edlib"], f"Finalizing genome {i+1}: {genomes_ori[i]}")
        run_cmd(["mv", f"{out_dir_consensus}/graph.with_haplome.haplome{i+1}.blocks.edlib.csv", f"{args.output}/final_blocks_{i+1}.csv"], f"Copying result {i+1}: {genomes_ori[i]}")
    logging(f"RSS (Resident Set Size): {max_memory_usage} bytes")

logging("GenomeDecoder finished")