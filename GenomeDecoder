#!/usr/bin/env python
import argparse
import datetime
import os
import subprocess
import psutil
import sys
import threading
import time
from itertools import combinations
import copy
import random
from Bio import SeqIO
from Bio.Seq import Seq
from Bio.SeqRecord import SeqRecord
import pandas as pd

max_memory_usage = 0
def monitor_memory_usage(interval=1):
    global max_memory_usage
    while True:
        total_memory = get_total_memory_usage()
        max_memory_usage = max(max_memory_usage, total_memory)
        time.sleep(interval)

def get_total_memory_usage():
    parent_process = psutil.Process(os.getpid())
    parent_memory = parent_process.memory_info().rss
    total_memory = parent_memory

    for child in parent_process.children(recursive=True):
        try:
            child_memory = child.memory_info().rss
            total_memory += child_memory
        except psutil.NoSuchProcess:
            continue
    return total_memory

# Start the memory monitoring in a separate thread
monitoring_thread = threading.Thread(target=monitor_memory_usage, args=(1,), daemon=True)
monitoring_thread.start()

def logging(message):
    print(f"[{datetime.datetime.now():%Y-%m-%d %H:%M:%S}] {message}", flush=True)

def run_cmd(command, name, verbose=True):
    if verbose:
        logging(f'{name}')
    if "-o" in command:
        index = command.index("-o")
        out = command[index + 1]
        log_file = out + ".log"
        with open(log_file, 'w') as f:
            ret = subprocess.run(command, stdout=f)
    else:
        ret = subprocess.run(command)
    if ret.returncode:
        logging(f'{name} fails: {" ".join(command)}')
        sys.exit(1)

def add_random_prefix_suffix(input_file, output_file, prefix_length=2000, suffix_length=2000, seed=None):
    if seed is None:
        seed = random.randint(0, 2**32 - 1)
    random.seed(seed)
    
    # Define the possible bases
    bases = ['A', 'T', 'C', 'G']
    
    def random_sequence(length):
        return ''.join(random.choices(bases, k=length))
    
    with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:
        seq_combined = ""
        prefix = random_sequence(prefix_length)
        suffix = random_sequence(suffix_length)
        for record in SeqIO.parse(infile, "fasta"):
            seq = str(record.seq).upper()
            seq_trans = ""
            for l in seq:
                if l not in ['A', 'T', 'C', 'G']:
                    seq_trans += random.choice(['A', 'T', 'C', 'G'])
                else:
                    seq_trans += l

            if seq_combined == "":
                seq_combined += seq_trans
            else:
                seq_combined += ("N"*2000 + seq_trans)
        new_seq = Seq(prefix + seq_combined + suffix)
        new_record = SeqRecord(new_seq, id=record.id, description=record.description)
        SeqIO.write(new_record, outfile, "fasta")
    
def adjust_coordinates(blocks):
    df = pd.read_csv(blocks, sep = '\t')
    df["End Pos in Original Sequence"] -= 2000
    df["Start Pos in Original Sequence"] -= 2000

    df.loc[df["End Pos in Original Sequence"]<=0, "End Pos in Original Sequence"] = 0
    df.loc[df["Start Pos in Original Sequence"]<=0, "Start Pos in Original Sequence"] = 0

    df.iloc[len(df)-1, 9] -= 2000
    df["Length in Original Sequence"] = df["End Pos in Original Sequence"] - df["Start Pos in Original Sequence"]
    df = df.loc[df["Length in Original Sequence"] >= 2000]
    df.to_csv(blocks, index=None, sep='\t')

def get_coordinates(align_out, genome_ori, genome, blocks, output):
    if aligner == "edlib":
        run_cmd([f"{dirname}/src/edlib_align", genome_ori, genome, align_out], f"Aligning transformed sequence {genome} to original sequence {genome_ori}")
    else:
        run_cmd([f"{dirname}/src/unialigner/tandem_aligner/build/bin/tandem_aligner", "--first", genome_ori, "--second", genome, "-o", align_out], f"Aligning transformed sequence {genome} to original sequence {genome_ori}")
    run_cmd([f"{dirname}/src/parse_cigar.py", f"{align_out}/cigar.txt", blocks, aligner], f"Finalizing genome {genome_ori}")
    run_cmd(["mv", f"{blocks}.{aligner}.csv", output], f"Copying result {output}")
    adjust_coordinates(output)

parser = argparse.ArgumentParser()
parser.add_argument(
    "-g",
    "--genome",
    required=True,
    action="append",
    help="Specifies the path to the genome file to be analyzed. This argument is required. Each input genome should contain a single contig and be masked using RepeatMasker (in the case of a multi-chromosomal genome, all chromosomes/contigs are concatenated in a single string using 2000 \"N\"s as separators automatically). Use -g multiple times to compare multiple genomes."
)
parser.add_argument(
    "-i",
    "--iterations",
    required=False,
    type=int,
    default=5,
    help="Specifies the number of iterations to use, applicable for disembroiling more than two input genomes. The default value is 5."
)
parser.add_argument(
    "-k",
    "--k_values",
    required=False,
    default="31,51,101,201,401,801,2001",
    help="Defines K-mer values for graph transformations. The default values are 31,51,101,201,401,801,2001. For highly complex regions, another recommended setting is \"-k 21,25,31,51,101,201,401,801,2001\" to produce more detailed SD blocks."
)
parser.add_argument(
    "-s",
    "--simple",
    required=False,
    default="0",
    type=str,
    help="Sets the similarity threshold for collapsing simple bubbles. The default value is 0, which is suitable for most datasets."
)
parser.add_argument(
    "-c",
    "--complex",
    required=False,
    default="0.65",
    type=str,
    help="Sets the similarity threshold for collapsing complex bubbles. The default value is 0.65, which is suitable for most datasets."
)
# parser.add_argument(
#     "-a",
#     "--aligner",
#     required=False,
#     default="edlib",
#     type=str,
#     help="The alignment tool for global alignment between disembroiled genome and original genome. Edlib is defalut and recommended. Choose from Edlib and UniAligner. UniAligner is 10x faster but less stable for tandem repeats (optional)"
# )
parser.add_argument(
    "-o",
    "--output",
    required=True,
    help="Specifies the output directory where GenomeDecoder will save the results. This argument is required."
)

args = parser.parse_args()

# if (os.path.isdir(args.output)):
#     logging(f"Output directory {args.output} already exists.")
#     exit(1)

k_values = args.k_values.split(',')
if len(k_values) < 2:
    logging(f"K should be more than 2 values.")
    exit(1)

if int(k_values[0]) < 20:
    logging(f"We recommend the smallest k to be 21.")
    exit(1)

aligner = "edlib"

pid = os.getpid()
process = psutil.Process(pid)
logging("GenomeDecoder starts")
logging(f"RSS (Resident Set Size): {max_memory_usage} bytes")
# create output directory
if not os.path.isdir(args.output):
    run_cmd(["mkdir", args.output], "Making output dir")

# get py dir
dirname, filename = os.path.split(os.path.abspath(__file__))

genomes = args.genome
genomes_to_run = []
for i, g in enumerate(genomes):
    add_random_prefix_suffix(g, f"{args.output}/original_genome_{i+1}.fa")
    genomes_to_run.append(f"{args.output}/original_genome_{i+1}.fa")

if len(genomes_to_run) == 1:
    genome1_ori = os.path.realpath(genomes_to_run[0])
    genome1 = os.path.realpath(genomes_to_run[0])

    out = f"{k_values[-1]}.1"
    out_dir_consensus = f"{args.output}/consensus.k{out}"
    genome1_transformed = f"{out_dir_consensus}/graph.with_haplome.haplome1.fa"

    if not os.path.isfile(genome1_transformed):
        k = k_values[0]
        out_dir_graph = f"{args.output}/jumbodbg.consensus.k{k}"
        dot_graph = f"{out_dir_graph}/graph.dot"
        fa_graph = f"{out_dir_graph}/graph.fasta"
        out_dir_consensus = f"{args.output}/consensus.k{k}"
        run_cmd(["jumboDBG", "--reads", genome1, "-t", "25", "-k", k, "-o", out_dir_graph, "--coverage"], f"Graph construction for k={k}")
        run_cmd([f"{dirname}/src/consensus_asm", "-d", dot_graph, "-f", fa_graph, "-1", genome1, "-k", k, "-o", out_dir_consensus, "--only_simple_bulge", "-s", "0.9"], f"Graph transformation for k={k}")
        genome1 = f"{out_dir_consensus}/graph.final.haplome1.fa"

        for k in k_values[1:]:
            out_dir_graph = f"{args.output}/jumbodbg.consensus.k{k}"
            dot_graph = f"{out_dir_graph}/graph.dot"
            fa_graph = f"{out_dir_graph}/graph.fasta"
            out_dir_consensus = f"{args.output}/consensus.k{k}"
            run_cmd(["jumboDBG", "--reads", genome1, "-t", "25", "-k", k, "-o", out_dir_graph, "--coverage"], f"Graph construction for k={k}")
            run_cmd([f"{dirname}/src/consensus_asm", "-d", dot_graph, "-f", fa_graph, "-1", genome1, "-k", k, "-o", out_dir_consensus, "-s", args.simple, "-c", args.complex], f"Graph transformation for k={k}")
            genome1 = f"{out_dir_consensus}/graph.final.haplome1.fa"

        out = f"{k}.1"
        out_dir_graph = f"{args.output}/jumbodbg.consensus.k{out}"
        dot_graph = f"{out_dir_graph}/graph.dot"
        fa_graph = f"{out_dir_graph}/graph.fasta"
        out_dir_consensus = f"{args.output}/consensus.k{out}"
        run_cmd(["jumboDBG", "--reads", genome1, "-t", "25", "-k", k, "-o", out_dir_graph, "--coverage"], f"Graph construction for k={k}")
        run_cmd([f"{dirname}/src/consensus_asm", "-d", dot_graph, "-f", fa_graph, "-1", genome1, "-k", k, "-o", out_dir_consensus, "-s", args.simple, "-c", args.complex], f"Graph transformation for k={k}")
        # genome1 = f"{out_dir_consensus}/graph.final.haplome1.fa"
        logging(f"RSS (Resident Set Size): {max_memory_usage} bytes")
    else:
        genome1 = genome1_transformed
        logging("Restart from global alignment")

    align_1 = f"{out_dir_consensus}.{aligner}1"
    blocks_1 = f"{out_dir_consensus}/graph.with_haplome.haplome1.blocks"
    get_coordinates(align_1, genome1_ori, genome1, blocks_1, f"{args.output}/final_blocks_1.csv")
    logging(f"RSS (Resident Set Size): {max_memory_usage} bytes")

elif len(genomes_to_run) == 2:
    genome1_ori = os.path.realpath(genomes_to_run[0])
    genome2_ori = os.path.realpath(genomes_to_run[1])
    genome1 = os.path.realpath(genomes_to_run[0])
    genome2 = os.path.realpath(genomes_to_run[1])

    out = f"{k_values[-1]}.1"
    out_dir_consensus = f"{args.output}/consensus.k{out}"
    genome1_transformed = f"{out_dir_consensus}/graph.with_haplome.haplome1.fa"
    genome2_transformed = f"{out_dir_consensus}/graph.with_haplome.haplome2.fa"

    if not os.path.isfile(genome1_transformed) or not os.path.isfile(genome2_transformed):
        k = k_values[0]
        out_dir_graph = f"{args.output}/jumbodbg.consensus.k{k}"
        dot_graph = f"{out_dir_graph}/graph.dot"
        fa_graph = f"{out_dir_graph}/graph.fasta"
        out_dir_consensus = f"{args.output}/consensus.k{k}"
        run_cmd(["jumboDBG", "--reads", genome1, "--reads", genome2, "-t", "25", "-k", k, "-o", out_dir_graph, "--coverage"], f"Graph construction for k={k}")
        run_cmd([f"{dirname}/src/consensus_asm", "-d", dot_graph, "-f", fa_graph, "-1", genome1, "-2", genome2, "-k", k, "-o", out_dir_consensus, "--only_simple_bulge", "-s", "0.9"], f"Graph transformation for k={k}")
        genome1 = f"{out_dir_consensus}/graph.final.haplome1.fa"
        genome2 = f"{out_dir_consensus}/graph.final.haplome2.fa"

        for k in k_values[1:]:
            out_dir_graph = f"{args.output}/jumbodbg.consensus.k{k}"
            dot_graph = f"{out_dir_graph}/graph.dot"
            fa_graph = f"{out_dir_graph}/graph.fasta"
            out_dir_consensus = f"{args.output}/consensus.k{k}"
            run_cmd(["jumboDBG", "--reads", genome1, "--reads", genome2, "-t", "25", "-k", k, "-o", out_dir_graph, "--coverage"], f"Graph construction for k={k}")
            run_cmd([f"{dirname}/src/consensus_asm", "-d", dot_graph, "-f", fa_graph, "-1", genome1, "-2", genome2, "-k", k, "-o", out_dir_consensus, "-s", args.simple, "-c", args.complex], f"Graph transformation for k={k}")
            genome1 = f"{out_dir_consensus}/graph.final.haplome1.fa"
            genome2 = f"{out_dir_consensus}/graph.final.haplome2.fa"

        out = f"{k}.1"
        out_dir_graph = f"{args.output}/jumbodbg.consensus.k{out}"
        dot_graph = f"{out_dir_graph}/graph.dot"
        fa_graph = f"{out_dir_graph}/graph.fasta"
        out_dir_consensus = f"{args.output}/consensus.k{out}"
        run_cmd(["jumboDBG", "--reads", genome1, "--reads", genome2, "-t", "25", "-k", k, "-o", out_dir_graph, "--coverage"], f"Graph construction for k={k}")
        run_cmd([f"{dirname}/src/consensus_asm", "-d", dot_graph, "-f", fa_graph, "-1", genome1, "-2", genome2, "-k", k, "-o", out_dir_consensus, "-s", args.simple, "-c", args.complex], f"Graph transformation for k={k}")
        # genome1 = f"{out_dir_consensus}/graph.final.haplome1.fa"
        # genome2 = f"{out_dir_consensus}/graph.final.haplome2.fa"
        logging(f"RSS (Resident Set Size): {max_memory_usage} bytes")
    else:
        genome1 = genome1_transformed
        genome2 = genome2_transformed
        logging("Restart from global alignment")

    align_1 = f"{out_dir_consensus}.{aligner}1"
    blocks_1 = f"{out_dir_consensus}/graph.with_haplome.haplome1.blocks"
    output_1 = f"{args.output}/final_blocks_1.csv"
    align_thread_1 = threading.Thread(target=get_coordinates, args=(align_1, genome1_ori, genome1, blocks_1, output_1,))
    align_thread_1.start()
    
    align_2 = f"{out_dir_consensus}.{aligner}2"
    blocks_2 = f"{out_dir_consensus}/graph.with_haplome.haplome2.blocks"
    output_2 = f"{args.output}/final_blocks_2.csv"
    align_thread_2 = threading.Thread(target=get_coordinates, args=(align_2, genome2_ori, genome2, blocks_2, output_2,))
    align_thread_2.start()

    align_thread_1.join()
    align_thread_2.join()
    logging(f"RSS (Resident Set Size): {max_memory_usage} bytes")

else:
    # how many iterations of full combinations
    genomes_ori = copy.deepcopy(genomes_to_run)
    for it in range(args.iterations):
        for index1, index2 in combinations(range(len(genomes_to_run)), 2):
            genome1 = os.path.realpath(genomes_to_run[index1])
            genome2 = os.path.realpath(genomes_to_run[index2])
            logging(f"Run synteny for {genome1} and {genome2}")
            
            output = f"{args.output}/{it}_genome{index1+1}_genome{index2+1}"
            run_cmd(["mkdir", output], "Making output dir")
            k = k_values[0]
            out_dir_graph = f"{output}/jumbodbg.consensus.k{k}"
            dot_graph = f"{out_dir_graph}/graph.dot"
            fa_graph = f"{out_dir_graph}/graph.fasta"
            out_dir_consensus = f"{output}/consensus.k{k}"
            run_cmd(["jumboDBG", "--reads", genome1, "--reads", genome2, "-t", "25", "-k", k, "-o", out_dir_graph, "--coverage"], f"Graph construction for k={k}")
            run_cmd([f"{dirname}/src/consensus_asm", "-d", dot_graph, "-f", fa_graph, "-1", genome1, "-2", genome2, "-k", k, "-o", out_dir_consensus, "--only_simple_bulge", "-s", "0.9"], f"Graph transformation for k={k}")
            genome1 = f"{out_dir_consensus}/graph.final.haplome1.fa"
            genome2 = f"{out_dir_consensus}/graph.final.haplome2.fa"

            for k in k_values[1:]:
                out_dir_graph = f"{output}/jumbodbg.consensus.k{k}"
                dot_graph = f"{out_dir_graph}/graph.dot"
                fa_graph = f"{out_dir_graph}/graph.fasta"
                out_dir_consensus = f"{output}/consensus.k{k}"
                run_cmd(["jumboDBG", "--reads", genome1, "--reads", genome2, "-t", "25", "-k", k, "-o", out_dir_graph, "--coverage"], f"Graph construction for k={k}")
                run_cmd([f"{dirname}/src/consensus_asm", "-d", dot_graph, "-f", fa_graph, "-1", genome1, "-2", genome2, "-k", k, "-o", out_dir_consensus, "-s", args.simple, "-c", args.complex], f"Graph transformation for k={k}")
                genome1 = f"{out_dir_consensus}/graph.final.haplome1.fa"
                genome2 = f"{out_dir_consensus}/graph.final.haplome2.fa"

            out = f"{k}.1"
            out_dir_graph = f"{output}/jumbodbg.consensus.k{out}"
            dot_graph = f"{out_dir_graph}/graph.dot"
            fa_graph = f"{out_dir_graph}/graph.fasta"
            out_dir_consensus = f"{output}/consensus.k{out}"
            run_cmd(["jumboDBG", "--reads", genome1, "--reads", genome2, "-t", "25", "-k", k, "-o", out_dir_graph, "--coverage"], f"Graph construction for k={k}")
            run_cmd([f"{dirname}/src/consensus_asm", "-d", dot_graph, "-f", fa_graph, "-1", genome1, "-2", genome2, "-k", k, "-o", out_dir_consensus, "-s", args.simple, "-c", args.complex], f"Graph transformation for k={k}")
            genome1 = f"{out_dir_consensus}/graph.final.haplome1.fa"
            genome2 = f"{out_dir_consensus}/graph.final.haplome2.fa"
            logging(f"RSS (Resident Set Size): {max_memory_usage} bytes")

            genomes_to_run[index1] = genome1
            genomes_to_run[index2] = genome2
    
    # jumboDBG
    out_dir_graph = f"{args.output}/jumbodbg_final"
    print("Run cmd:", " ".join(["jumboDBG", "--reads", " --reads ".join(genomes_to_run), "-t", "25", "-k", k, "-o", out_dir_graph, "--coverage"]))
    os.system(" ".join(["jumboDBG", "--reads", " --reads ".join(genomes_to_run), "-t", "25", "-k", k, "-o", out_dir_graph, "--coverage"]))
    dot_graph = f"{out_dir_graph}/graph.dot"
    fa_graph = f"{out_dir_graph}/graph.fasta"
    out_dir_consensus = f"{args.output}/consensus_final"
    run_cmd([f"{dirname}/src/synteny", "-d", dot_graph, "-f", fa_graph, "-h", ",".join(genomes_to_run), "-k", k, "-o", out_dir_consensus], f"Generate synteny blocks")
    logging(f"RSS (Resident Set Size): {max_memory_usage} bytes")

    threads = []
    for i in range(len(genomes_to_run)):
        align = f"{out_dir_consensus}.{aligner}{i+1}"
        blocks = f"{out_dir_consensus}/graph.with_haplome.haplome{i+1}.blocks"
        output = f"{args.output}/final_blocks_{i+1}.csv"
        align_thread = threading.Thread(target=get_coordinates, args=(align, genomes_ori[i],  genomes_to_run[i], blocks, output,))
        align_thread.start()
        threads.append(align_thread)
    for t in threads:
        t.join()
    logging(f"RSS (Resident Set Size): {max_memory_usage} bytes")

logging("GenomeDecoder finished")